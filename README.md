ğŸš€ Pipeline ETL com Arquitetura MedalhÃ£o: De Dados Brutos a Insights Reais
Este projeto foi desenvolvido como um desafio prÃ¡tico de Engenharia de Dados, focado na implementaÃ§Ã£o da Arquitetura MedalhÃ£o para transformar dados crus em uma visÃ£o analÃ­tica consolidada. Indo alÃ©m do conteÃºdo bÃ¡sico do curso, implementei rotinas de Data Quality, normalizaÃ§Ã£o de dados e anÃ¡lise exploratÃ³ria.

ğŸ—ï¸ A Arquitetura e o Fluxo de Dados
O pipeline segue a separaÃ§Ã£o lÃ³gica de responsabilidades para garantir escalabilidade e confianÃ§a no dado:

Camada Bronze (Raw): Armazenamento fiel dos dados brutos recebidos em formatos heterogÃªneos (CSV, JSON).

Camada Silver (Validated): Processo de limpeza e conversÃ£o. Aqui, os dados foram tipados e salvos em formato Parquet, otimizando o armazenamento e a performance de leitura.

Camada Gold (Enriched): Camada de consumo onde realizei o Inner Join entre UsuÃ¡rios e LocalizaÃ§Ã£o (CEP), criando uma visÃ£o de negÃ³cio pronta para BI.

ğŸ› ï¸ Tecnologias e Ferramentas
Linguagem: Python 3.x

Processamento de Dados: Pandas

Armazenamento: Parquet (Formatos colunares)

Banco de Dados: PostgreSQL (via Docker)

VisualizaÃ§Ã£o: Matplotlib & Seaborn

Ambiente: Jupyter Notebooks & VS Code

ğŸ’¡ Meus Diferenciais (O que adicionei ao projeto)
Para elevar o nÃ­vel tÃ©cnico da entrega, implementei as seguintes melhorias:

NormalizaÃ§Ã£o de GÃªnero: Identifiquei e corrigi inconsistÃªncias de strings (ex: "F " vs "F") que causavam duplicidade em anÃ¡lises estatÃ­sticas.

OrdenaÃ§Ã£o NumÃ©rica: Corrigi a lÃ³gica de ordenaÃ§Ã£o da Query Gold, realizando o CAST de IDs que estavam em formato string para Integer.

Data Visualization: Desenvolvi um Dashboard no data-view.ipynb para analisar a distribuiÃ§Ã£o de usuÃ¡rios por UF, GÃªnero e Ano de Nascimento.

Boas PrÃ¡ticas de DevOps: ConfiguraÃ§Ã£o de .gitignore profissional e gerenciamento de dependÃªncias via requirements.txt.

ğŸš€ Como Rodar o Projeto
Clone o repositÃ³rio:

Bash

git clone https://github.com/seu-usuario/seu-repositorio.git
cd seu-repositorio
Crie e ative seu ambiente virtual:

Bash

python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows
Instale as dependÃªncias:

Bash

pip install -r requirements.txt
Suba o banco de dados e rode o pipeline:

Bash

docker-compose up -d
python populate_db.py
python normalize_data.py
ğŸ“ˆ PrÃ³ximos Passos
Pretendo expandir este projeto integrando o arquivo products.json para criar uma Tabela Fato de Vendas, permitindo analisar o ticket mÃ©dio por regiÃ£o.